{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## Data Pre-processing\n",
    "\n",
    "先從置於同目錄下的 proc/ 讀取處理過的字幕資料，並利用 *jieba* 進行斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2944 lines from Inferno_2016.csv\n",
      "Read 3088 lines from Wonder_Woman_2017.csv\n",
      "Read 4437 lines from Inception_2010.csv\n",
      "Read 4485 lines from Spider-Man_Homecoming_2017.csv\n",
      "Read 3104 lines from Baby_Driver_2017.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from utils import read_csvdir, sep_train_test, accuracy\n",
    "from simple_nb import SimpleNB\n",
    "from binary_nb import BinaryNB\n",
    "from tfidf_nb import tfidfNB\n",
    "\n",
    "data_arr = read_csvdir('./proc', details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將所有訓練資料 shuffle，且依照 9:1 分為訓練資料與測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data = 16253\n",
      "# of test data     = 1805\n"
     ]
    }
   ],
   "source": [
    "train_arr, test_arr = sep_train_test(data_arr, ratio=0.1)\n",
    "test_Y, test_X = zip(*test_arr)\n",
    "\n",
    "print('# of training data =', len(train_arr))\n",
    "print('# of test data     =', len(test_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation and Test\n",
    "\n",
    "![cross-validation](https://raw.githubusercontent.com/ritchieng/machine-learning-dataschool/master/images/07_cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model_class, data, cv=5):\n",
    "    scores = []\n",
    "    nb_seg = len(data) // cv\n",
    "\n",
    "    print('Cross Validation')\n",
    "    for i in range(cv):\n",
    "        dev_data = data[i*nb_seg : (i+1)*nb_seg]\n",
    "        train_data = data[: i*nb_seg] + data[(i+1)*nb_seg :]\n",
    "        \n",
    "        dev_Y, dev_X = zip(*dev_data)\n",
    "        \n",
    "        model = model_class()\n",
    "        model.train(train_data)\n",
    "        preds = model.predict(dev_X)\n",
    "        score = f1_score(dev_Y, preds, average='macro')\n",
    "        scores.append(score)\n",
    "\n",
    "    print('  f1_score = [{}]'.format(', '.join(['{:4f}'.format(s) for s in scores])))\n",
    "    print('  {}-fold cross-validation f1_score = {:.4f}'.format(cv, sum(scores)/cv))\n",
    "\n",
    "def test(model_class, train_data, test_X, test_Y):\n",
    "    model = model_class()\n",
    "    model.train(train_data)\n",
    "    preds = model.predict(test_X)\n",
    "    \n",
    "    print('\\nTest')\n",
    "    print('  accuracy        = {:.4f}'.format(accuracy(test_Y, preds)))\n",
    "    print('  f1_score(micro) = {:.4f}'.format(f1_score(test_Y, preds, average='micro')))\n",
    "    print('  f1_score(macro) = {:.4f}'.format(f1_score(test_Y, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n",
      "  f1_score = [0.626305, 0.634632]\n",
      "  2-fold cross-validation f1_score = 0.6305\n",
      "\n",
      "Test\n",
      "  accuracy        = 0.6327\n",
      "  f1_score(micro) = 0.6327\n",
      "  f1_score(macro) = 0.6275\n"
     ]
    }
   ],
   "source": [
    "cross_val(SimpleNB, train_arr, cv=2)\n",
    "test(SimpleNB, train_arr, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarized Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n",
      "  f1_score = [0.618067, 0.624193, 0.622820, 0.629280, 0.639446]\n",
      "  5-fold cross-validation f1_score = 0.6268\n",
      "\n",
      "Test\n",
      "  accuracy        = 0.6343\n",
      "  f1_score(micro) = 0.6343\n",
      "  f1_score(macro) = 0.6189\n"
     ]
    }
   ],
   "source": [
    "cross_val(BinaryNB, train_arr, cv=5)\n",
    "test(BinaryNB, train_arr, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n",
      "  f1_score = [0.616320, 0.628998]\n",
      "  2-fold cross-validation f1_score = 0.6227\n",
      "\n",
      "Test\n",
      "  accuracy        = 0.6382\n",
      "  f1_score(micro) = 0.6382\n",
      "  f1_score(macro) = 0.6307\n"
     ]
    }
   ],
   "source": [
    "cross_val(tfidfNB, train_arr, cv=2)\n",
    "test(tfidfNB, train_arr, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
