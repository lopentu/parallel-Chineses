{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## Data Pre-processing\n",
    "\n",
    "先從置於同目錄下的 proc/ 讀取處理過的字幕資料，並利用 *jieba* 進行斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/jt/ms93_ljx2mvgwxx24xrlw03r0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2944 lines from Inferno_2016.csv\n",
      "Read 6516 lines from Schindlers_List_1993.csv\n",
      "Read 3088 lines from Wonder_Woman_2017.csv\n",
      "Read 4437 lines from Inception_2010.csv\n",
      "Read 4485 lines from Spider-Man_Homecoming_2017.csv\n",
      "Read 3104 lines from Baby_Driver_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.023 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from utils import read_csvdir, sep_train_test, accuracy\n",
    "from simple_nb import SimpleNB\n",
    "from binary_nb import BinaryNB\n",
    "from tfidf_nb import tfidfNB\n",
    "\n",
    "data_arr = read_csvdir('./proc', details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將所有訓練資料 shuffle，且依照 9:1 分為訓練資料與測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data = 22117\n",
      "# of test data     = 2457\n"
     ]
    }
   ],
   "source": [
    "train_arr, test_arr = sep_train_test(data_arr, ratio=0.1)\n",
    "test_Y, test_X = zip(*test_arr)\n",
    "\n",
    "print('# of training data =', len(train_arr))\n",
    "print('# of test data     =', len(test_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation and Test\n",
    "\n",
    "![cross-validation](https://raw.githubusercontent.com/ritchieng/machine-learning-dataschool/master/images/07_cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model_class, data, cv=5):\n",
    "    scores = []\n",
    "    nb_seg = len(data) // cv\n",
    "\n",
    "    print('Cross Validation')\n",
    "    for i in range(cv):\n",
    "        dev_data = data[i*nb_seg : (i+1)*nb_seg]\n",
    "        train_data = data[: i*nb_seg] + data[(i+1)*nb_seg :]\n",
    "        \n",
    "        dev_Y, dev_X = zip(*dev_data)\n",
    "        \n",
    "        model = model_class()\n",
    "        model.train(train_data)\n",
    "        preds = model.predict(dev_X)\n",
    "        \n",
    "        score = f1_score(dev_Y, preds, average='macro')\n",
    "        scores.append(score)\n",
    "\n",
    "    print('  f1_score = [{}]'.format(', '.join(['{:4f}'.format(s) for s in scores])))\n",
    "    print('  {}-fold cross-validation f1_score = {:.4f}'.format(cv, sum(scores)/cv))\n",
    "\n",
    "def test(model_class, train_data, test_X, test_Y):\n",
    "    model = model_class()\n",
    "    model.train(train_data)\n",
    "    preds = model.predict(test_X)\n",
    "    \n",
    "    print('\\nTest')\n",
    "    print('  accuracy        = {:.4f}'.format(accuracy(test_Y, preds)))\n",
    "    print('  f1_score(micro) = {:.4f}'.format(f1_score(test_Y, preds, average='micro')))\n",
    "    print('  f1_score(macro) = {:.4f}'.format(f1_score(test_Y, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n",
      "  f1_score = [0.642867, 0.633875, 0.630873, 0.624296, 0.623581]\n",
      "  5-fold cross-validation f1_score = 0.6311\n",
      "\n",
      "Test\n",
      "  accuracy        = 0.6422\n",
      "  f1_score(micro) = 0.6422\n",
      "  f1_score(macro) = 0.6234\n"
     ]
    }
   ],
   "source": [
    "cross_val(SimpleNB, train_arr, cv=5)\n",
    "test(SimpleNB, train_arr, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarized Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n",
      "  f1_score = [0.609302, 0.617092, 0.602089, 0.602649, 0.606567]\n",
      "  5-fold cross-validation f1_score = 0.6075\n",
      "\n",
      "Test\n",
      "  accuracy        = 0.6593\n",
      "  f1_score(micro) = 0.6593\n",
      "  f1_score(macro) = 0.6140\n"
     ]
    }
   ],
   "source": [
    "cross_val(BinaryNB, train_arr, cv=5)\n",
    "test(BinaryNB, train_arr, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-89f93187cc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidfNB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidfNB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-aff21a226bb5>\u001b[0m in \u001b[0;36mcross_val\u001b[0;34m(model_class, data, cv)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/LTCL_2017_fall/parallel-Chineses/NB/cs+/tfidf_nb.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# calculate tfidf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mtfidf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidfNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mtfidf_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CN'"
     ]
    }
   ],
   "source": [
    "cross_val(tfidfNB, train_arr, cv=5)\n",
    "test(tfidfNB, train_arr, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
